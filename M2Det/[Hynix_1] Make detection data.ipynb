{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# from data_aug.data_aug import *\n",
    "# from data_aug.bbox_util import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2017 = \"/home/ubunt/M2Det_data/Hynix data/2017_2018_img/\"\n",
    "whole_csv_path = \"/home/ubunt/M2Det_data/Python script/\"\n",
    "af_path_2017 = \"/home/ubunt/M2Det_data/Hynix data/2017_2018_img_af/\"\n",
    "image_path_2017 = af_path_2017 + \"*.bmp\"\n",
    "csv_path_2017 = path_2017 + \"*.csv\"\n",
    "cropped_path_2017 = \"/home/ubunt/M2Det_data/Hynix data/2017_2018_img_cropped/\"\n",
    "image_path_recent = \"/home/ubunt/M2Det_data/Hynix data/labeled_imgs_recent/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 이미지 확인\n",
    "def select_image_recent(img_path, file_name) :\n",
    "    image_path = [x for x in sorted(img_path) if file_name in x][0]\n",
    "    image = Image.open(image_path)\n",
    "    image_np = np.array(image)\n",
    "    return image, image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_key(file_name, df) :\n",
    "    output = df.loc[df['IMG_NAME'] == file_name + \".jpg\", 'ROW_UNIQUE_KEY'].tolist()\n",
    "    #print(df.loc[df['IMG_NAME'] == file_name + \".jpg\", 'ROW_UNIQUE_KEY'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_two_data(whole_csv, margin) :\n",
    "    cropped_data, bbox_data = whole_csv.copy(), whole_csv.copy()\n",
    "    cropped_data['P_X1'] = [x - margin for x in cropped_data['P_X1']]\n",
    "    cropped_data['P_X2'] = [x + margin for x in cropped_data['P_X2']]\n",
    "    cropped_data['P_Y1'] = [x - margin for x in cropped_data['P_Y1']]\n",
    "    cropped_data['P_Y2'] = [x + margin for x in cropped_data['P_Y2']]\n",
    "    \n",
    "    bbox_data['P_X1'] = [y - x for x,y in zip(cropped_data['P_X1'], bbox_data['P_X1'])]\n",
    "    bbox_data['P_Y1'] = [y - x for x,y in zip(cropped_data['P_Y1'], bbox_data['P_Y1'])]\n",
    "    bbox_data['P_X2'] = [x + y for x,y in zip(bbox_data['P_X1'], bbox_data['diff_x'])]\n",
    "    bbox_data['P_Y2'] = [x + y for x,y in zip(bbox_data['P_Y1'], bbox_data['diff_y'])]\n",
    "    \n",
    "    # range_x, range_y\n",
    "    bbox_data['range_x'] = [y - x for x,y in zip(cropped_data['P_X1'], cropped_data['P_X2'])]\n",
    "    bbox_data['range_y'] = [y - x for x,y in zip(cropped_data['P_Y1'], cropped_data['P_Y2'])]\n",
    "    \n",
    "    # label ratio\n",
    "    bbox_data['label_x1'] = [int(np.round((x / y) * 320)) for x,y in zip(bbox_data['P_X1'], bbox_data['range_x'])]\n",
    "    bbox_data['label_y1'] = [int(np.round((x / y) * 320)) for x,y in zip(bbox_data['P_Y1'], bbox_data['range_y'])]\n",
    "    bbox_data['label_x2'] = [int(np.round((x / y) * 320)) for x,y in zip(bbox_data['P_X2'], bbox_data['range_x'])]\n",
    "    bbox_data['label_y2'] = [int(np.round((x / y) * 320)) for x,y in zip(bbox_data['P_Y2'], bbox_data['range_y'])]\n",
    "    \n",
    "    return cropped_data, bbox_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = [\"2019_08_18\",\"2019_08_19\",\"2019_08_20\",\"2019_08_21\"]\n",
    "img_path = []\n",
    "\n",
    "for date in date_list :\n",
    "    csv_path = [x for x in glob(image_path_recent + date + \"/*\") if \".csv\" in x]\n",
    "    folder_path = [x for x in glob(image_path_recent + date + \"/*\") if \".csv\" not in x]\n",
    "    for path in folder_path :\n",
    "        img_path.extend(glob(path+ \"/*.jpg\"))\n",
    "    csv_date = pd.read_csv(csv_path[0])\n",
    "    del csv_date['Unnamed: 0']\n",
    "    if date == \"2019_08_18\" :\n",
    "        whole_csv = csv_date.copy()\n",
    "    else :\n",
    "        whole_csv = whole_csv.append(csv_date)\n",
    "whole_csv.index = [x for x in range(whole_csv.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_list = [True if x != 0 else False for x in whole_csv['P_X1']]\n",
    "whole_csv = whole_csv.loc[select_list,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_csv['diff_x'] = [y - x for x,y in zip(whole_csv['P_X1'], whole_csv['P_X2'])]\n",
    "whole_csv['diff_y'] = [y - x for x,y in zip(whole_csv['P_Y1'], whole_csv['P_Y2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>LOT</th>\n",
       "      <th>IMG_NAME</th>\n",
       "      <th>ROW_UNIQUE_KEY</th>\n",
       "      <th>PART</th>\n",
       "      <th>R_X1</th>\n",
       "      <th>R_Y1</th>\n",
       "      <th>R_X2</th>\n",
       "      <th>R_Y2</th>\n",
       "      <th>P_X1</th>\n",
       "      <th>P_Y1</th>\n",
       "      <th>P_X2</th>\n",
       "      <th>P_Y2</th>\n",
       "      <th>DEFECT_CLASS</th>\n",
       "      <th>diff_x</th>\n",
       "      <th>diff_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>2019_08_18_LOT_A5</td>\n",
       "      <td>2019_08_18_LOT_A5_K_01_41.jpg</td>\n",
       "      <td>2019_08_18_LOT_A5_K_01_41_0</td>\n",
       "      <td>Cap</td>\n",
       "      <td>624</td>\n",
       "      <td>298</td>\n",
       "      <td>630</td>\n",
       "      <td>300</td>\n",
       "      <td>622</td>\n",
       "      <td>280</td>\n",
       "      <td>633</td>\n",
       "      <td>301</td>\n",
       "      <td>fail</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>2019_08_18_LOT_A5</td>\n",
       "      <td>2019_08_18_LOT_A5_K_00_25.jpg</td>\n",
       "      <td>2019_08_18_LOT_A5_K_00_25_0</td>\n",
       "      <td>Cap</td>\n",
       "      <td>381</td>\n",
       "      <td>1745</td>\n",
       "      <td>402</td>\n",
       "      <td>1756</td>\n",
       "      <td>381</td>\n",
       "      <td>1745</td>\n",
       "      <td>402</td>\n",
       "      <td>1756</td>\n",
       "      <td>fail</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>2019_08_18_LOT_A5</td>\n",
       "      <td>2019_08_18_LOT_A5_K_01_09.jpg</td>\n",
       "      <td>2019_08_18_LOT_A5_K_01_09_0</td>\n",
       "      <td>Cap</td>\n",
       "      <td>582</td>\n",
       "      <td>2698</td>\n",
       "      <td>588</td>\n",
       "      <td>2701</td>\n",
       "      <td>582</td>\n",
       "      <td>2681</td>\n",
       "      <td>592</td>\n",
       "      <td>2703</td>\n",
       "      <td>fail</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE                LOT                       IMG_NAME  \\\n",
       "0  2019-08-18  2019_08_18_LOT_A5  2019_08_18_LOT_A5_K_01_41.jpg   \n",
       "1  2019-08-18  2019_08_18_LOT_A5  2019_08_18_LOT_A5_K_00_25.jpg   \n",
       "2  2019-08-18  2019_08_18_LOT_A5  2019_08_18_LOT_A5_K_01_09.jpg   \n",
       "\n",
       "                ROW_UNIQUE_KEY PART  R_X1  R_Y1  R_X2  R_Y2  P_X1  P_Y1  P_X2  \\\n",
       "0  2019_08_18_LOT_A5_K_01_41_0  Cap   624   298   630   300   622   280   633   \n",
       "1  2019_08_18_LOT_A5_K_00_25_0  Cap   381  1745   402  1756   381  1745   402   \n",
       "2  2019_08_18_LOT_A5_K_01_09_0  Cap   582  2698   588  2701   582  2681   592   \n",
       "\n",
       "   P_Y2 DEFECT_CLASS  diff_x  diff_y  \n",
       "0   301         fail      11      21  \n",
       "1  1756         fail      21      11  \n",
       "2  2703         fail      10      22  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_csv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_list = [True if x != \"Tab\" else False for x in whole_csv.PART]\n",
    "whole_csv = whole_csv.loc[select_list,:]\n",
    "whole_csv.index = [x for x in range(whole_csv.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_csv.loc[whole_csv.PART == \"Res\",:].IMG_NAME.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_csv = pd.read_csv(\"whole_csv_correct_finish_res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_data, bbox_data = make_two_data(whole_csv,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"dataset\"\n",
    "wd = '/home/jeon/Desktop/k-lab/train_our_data_M2Det/M2Det/data/'\n",
    "Annotations_path = wd+\"{}/Annotations/\".format(folder_name)\n",
    "Image_save_path = wd+\"{}/JPEGImages/\".format(folder_name)\n",
    "txt_save_path = wd+\"{}/ImageSets/Main/\".format(folder_name)\n",
    "val_save_path = wd+\"{}/test set/\".format(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop Image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_name_set = bbox_data.IMG_NAME.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_name_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e32b64bd76c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_name_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_image_recent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcropped_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcropped_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IMG_NAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ROW_UNIQUE_KEY2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PART'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'P_X1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"P_Y1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"P_X2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"P_Y2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROW_UNIQUE_KEY2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_name_set' is not defined"
     ]
    }
   ],
   "source": [
    "for name in tqdm_notebook(unique_name_set) :\n",
    "    image, image_np = select_image_recent(img_path, name)\n",
    "    tmp_df = cropped_data.loc[cropped_data['IMG_NAME'] == name,['ROW_UNIQUE_KEY2','PART','P_X1',\"P_Y1\",\"P_X2\",\"P_Y2\"]]\n",
    "    \n",
    "    for idx2,key in enumerate(tmp_df.ROW_UNIQUE_KEY2) :\n",
    "        crop_image = image.crop((tmp_df.loc[tmp_df['ROW_UNIQUE_KEY2'] == key,'P_X1'].iloc[0],\n",
    "                                tmp_df.loc[tmp_df['ROW_UNIQUE_KEY2'] == key,'P_Y1'].iloc[0],\n",
    "                                tmp_df.loc[tmp_df['ROW_UNIQUE_KEY2'] == key,'P_X2'].iloc[0],\n",
    "                                tmp_df.loc[tmp_df['ROW_UNIQUE_KEY2'] == key,'P_Y2'].iloc[0],\n",
    "                               ))\n",
    "        resize_image = crop_image.resize((320,320))\n",
    "        resize_image.save(Image_save_path + key + \".jpg\")\n",
    "        if \"2019_08_18\" in key or (\"LL4\" in tmp_df.PART.iloc[idx2]) :\n",
    "            if not os.path.isdir(val_save_path + tmp_df.PART.iloc[0]) :\n",
    "                os.mkdir(val_save_path + tmp_df.PART.iloc[idx2])\n",
    "            resize_image.save(val_save_path + tmp_df.PART.iloc[idx2] + \"/\" + key + \".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bbox = bbox_data.loc[:,['IMG_NAME','ROW_UNIQUE_KEY2','PART','label_x1','label_y1','label_x2','label_y2']]\n",
    "final_bbox.index = [x for x in range(final_bbox.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_key_set = bbox_data.ROW_UNIQUE_KEY2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300f4023d9e7403d93f05107ff22a2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13414), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm_notebook(unique_key_set) :\n",
    "    tmp_df = final_bbox.loc[final_bbox.ROW_UNIQUE_KEY2 == key, :]\n",
    "    # root\n",
    "    anootation = ET.Element('annotation')\n",
    "    # folder\n",
    "    folder = ET.SubElement(anootation, 'folder')\n",
    "    folder.text = \"Hynix_train\"\n",
    "    # filename\n",
    "    filename = ET.SubElement(anootation, 'filename')\n",
    "    # 2007_000027.jpg\n",
    "    filename.text = key + \".jpg\" # '2019_08_18_LOT_A5_K_00_41_4.jpg'\n",
    "    # path\n",
    "    path = ET.SubElement(anootation, 'path')\n",
    "    # /my/path/GeneratedData_Train/000001.png\n",
    "    path.text = \"/home/yjchoi/data/{}/JPEGImages/\".format(folder_name) + key + \".jpg\" \n",
    "    # souce\n",
    "    source = ET.SubElement(anootation, 'source')\n",
    "    database = ET.SubElement(source, 'database')\n",
    "    database.text = folder_name\n",
    "    # size\n",
    "    size = ET.SubElement(anootation, 'size')\n",
    "    width = ET.SubElement(size, 'width')\n",
    "    width.text = str(320)\n",
    "    height = ET.SubElement(size, 'height')\n",
    "    height.text= str(320)\n",
    "    depth = ET.SubElement(size, 'depth')\n",
    "    depth.text = str(3)\n",
    "    # segmented\n",
    "    segmented = ET.SubElement(anootation, 'segmented')\n",
    "    segmented.text = str(0)\n",
    "    for i in range(tmp_df.shape[0]) :\n",
    "        # object\n",
    "        object = ET.SubElement(anootation, 'object')\n",
    "        name = ET.SubElement(object, 'name')\n",
    "        name.text = tmp_df['PART'].iloc[i]\n",
    "        pose = ET.SubElement(object, 'pose')\n",
    "        pose.text = \"Unspecified\"\n",
    "        truncated = ET.SubElement(object, 'truncated')\n",
    "        truncated.text = str(0)\n",
    "        difficult = ET.SubElement(object, 'difficult')\n",
    "        difficult.text = str(0)\n",
    "        occluded = ET.SubElement(object, 'occluded')\n",
    "        occluded.text = str(0)\n",
    "        bndbox = ET.SubElement(object, 'bndbox')\n",
    "        xmin = ET.SubElement(bndbox, 'xmin')\n",
    "        xmin.text = str(int(tmp_df['label_x1'].iloc[i]))\n",
    "        xmax = ET.SubElement(bndbox, 'xmax')\n",
    "        xmax.text = str(int(tmp_df['label_x2'].iloc[i]))\n",
    "        ymin = ET.SubElement(bndbox, 'ymin')\n",
    "        ymin.text = str(int(tmp_df['label_y1'].iloc[i]))\n",
    "        ymax = ET.SubElement(bndbox, 'ymax')\n",
    "        ymax.text = str(int(tmp_df['label_y2'].iloc[i]))\n",
    "\n",
    "    # create a new XML file with the results\n",
    "    mydata = ET.tostring(anootation)\n",
    "    #myfile = open(Annotations_path + key + plus_name + \".xml\", \"w\")\n",
    "    myfile = open(Annotations_path + key + \".xml\", \"w\")\n",
    "    myfile.write(str(mydata)[2:(len(str(mydata))-1)])\n",
    "    while True :\n",
    "        if not myfile.closed :\n",
    "            myfile.close()\n",
    "        else :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ffef03bc364b29b4830710b89c19e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13414), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "whole_train_txt = open(txt_save_path + \"whole_train.txt\", 'a')\n",
    "for key in tqdm_notebook(unique_key_set) :\n",
    "    whole_train_txt.write(key + \"\\n\")\n",
    "whole_train_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_part_set = final_bbox.PART.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8cebde49be42a18bc7e115263e33ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_txt = open(txt_save_path + \"train.txt\", 'a')\n",
    "for key,part in tqdm_notebook(zip(unique_key_set,unique_part_set)) :\n",
    "    if part == \"LL8\" or \"2019_08_18\" not in key :\n",
    "        train_txt.write(key + \"\\n\")\n",
    "train_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5333b1dbdaeb45bab31923c5a3340909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13414), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_txt = open(txt_save_path + \"val.txt\", 'a')\n",
    "for key in tqdm_notebook(unique_key_set) :\n",
    "    if \"2019_08_18\" in key :\n",
    "        val_txt.write(key + \"\\n\")\n",
    "val_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
